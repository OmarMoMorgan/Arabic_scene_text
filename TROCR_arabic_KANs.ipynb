{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:26:22.999042Z","iopub.status.busy":"2024-05-22T09:26:22.998247Z","iopub.status.idle":"2024-05-22T09:27:02.405982Z","shell.execute_reply":"2024-05-22T09:27:02.404783Z","shell.execute_reply.started":"2024-05-22T09:26:22.999003Z"},"trusted":true},"outputs":[],"source":["! if [ ! $pip_done ]; then pip install -q transformers ;fi \n","! if [ ! $pip_done ]; then pip install -q datasets jiwer ;fi \n","! if [ ! $pip_done ]; then pip install -q sentencepiece ;fi \n","\n","pip_done = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:35:40.358138Z","iopub.status.busy":"2024-05-22T09:35:40.357742Z","iopub.status.idle":"2024-05-22T09:35:41.630785Z","shell.execute_reply":"2024-05-22T09:35:41.629633Z","shell.execute_reply.started":"2024-05-22T09:35:40.358105Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/OmarMoMorgan/Arabic_scene_text.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:30:49.675804Z","iopub.status.busy":"2024-05-22T09:30:49.675422Z","iopub.status.idle":"2024-05-22T09:30:49.682458Z","shell.execute_reply":"2024-05-22T09:30:49.681503Z","shell.execute_reply.started":"2024-05-22T09:30:49.675769Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AdamW\n","from sklearn.model_selection import train_test_split\n","from torch import nn , optim\n","\n","\n","import sys\n","sys.path.append('/kaggle/working/Arabic_scene_text') #change this to the name of the repo\n","from models import build_model , KAN\n","from tools import EarlyStopping, tune_model , replace_specific_layers , generate_text_with_caption\n","from data import train_test_split_ , perPixel_mean_std, perChannel_mean_std, build_transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:14.381628Z","iopub.status.busy":"2024-05-22T09:29:14.380560Z","iopub.status.idle":"2024-05-22T09:29:14.427690Z","shell.execute_reply":"2024-05-22T09:29:14.427006Z","shell.execute_reply.started":"2024-05-22T09:29:14.381593Z"},"trusted":true},"outputs":[],"source":["root_dir = \"/kaggle/input/str-arabic-dataset/Arabic_words_train\"\n","column_names = ['image_path', 'text']\n","df = pd.read_csv(\"/kaggle/input/str-arabic-dataset/Arabic_words_train/gt.txt\", nrows = 4186, names = column_names)\n","\n","\n","test_size = 0.2\n","train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n","\n","test_df , val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:16.599260Z","iopub.status.busy":"2024-05-22T09:29:16.598594Z","iopub.status.idle":"2024-05-22T09:29:16.603998Z","shell.execute_reply":"2024-05-22T09:29:16.603138Z","shell.execute_reply.started":"2024-05-22T09:29:16.599227Z"},"trusted":true},"outputs":[],"source":["train_df.reset_index(drop=True, inplace=True)\n","val_df.reset_index(drop=True, inplace=True)\n","test_df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:19.713474Z","iopub.status.busy":"2024-05-22T09:29:19.712562Z","iopub.status.idle":"2024-05-22T09:29:19.725358Z","shell.execute_reply":"2024-05-22T09:29:19.724374Z","shell.execute_reply.started":"2024-05-22T09:29:19.713440Z"},"trusted":true},"outputs":[],"source":["train_df.shape, val_df,test_df.shape"]},{"cell_type":"markdown","metadata":{},"source":["Making the data loader here "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:24.173840Z","iopub.status.busy":"2024-05-22T09:29:24.173134Z","iopub.status.idle":"2024-05-22T09:29:24.182900Z","shell.execute_reply":"2024-05-22T09:29:24.181794Z","shell.execute_reply.started":"2024-05-22T09:29:24.173804Z"},"trusted":true},"outputs":[],"source":["class ArabicSTRDataset(Dataset):\n","    def __init__(self, root_dir, df, processor, tokenizer, max_target_length):\n","        self.root_dir = root_dir\n","        self.df = df\n","        self.processor = processor\n","        self.tokenizer = tokenizer\n","        self.max_target_length = max_target_length\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # Get file name and text\n","        file_name = self.df.iloc[idx]['image_path']\n","        text = self.df.iloc[idx]['text']\n","\n","        # Prepare image (resize and normalize)\n","        image_path = f\"{self.root_dir}/{file_name}\"\n","        image = Image.open(image_path).convert(\"RGB\")\n","        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n","\n","        # Encode the text\n","        labels = self.tokenizer(text, padding=\"max_length\", max_length=self.max_target_length, return_tensors=\"pt\").input_ids\n","        labels = labels.squeeze()\n","        labels[labels == self.tokenizer.pad_token_id] = -100\n","\n","\n","        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": labels}\n","        return encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:26.043531Z","iopub.status.busy":"2024-05-22T09:29:26.042692Z","iopub.status.idle":"2024-05-22T09:29:26.076868Z","shell.execute_reply":"2024-05-22T09:29:26.075796Z","shell.execute_reply.started":"2024-05-22T09:29:26.043499Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["Making the pretrained model using gpt 2 as tokenizer and processor and for the backbone of the network we are using vision transormer with Deit archietcures and pretrained weights "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:29.320563Z","iopub.status.busy":"2024-05-22T09:29:29.319636Z","iopub.status.idle":"2024-05-22T09:29:45.583552Z","shell.execute_reply":"2024-05-22T09:29:45.582614Z","shell.execute_reply.started":"2024-05-22T09:29:29.320530Z"},"trusted":true},"outputs":[],"source":["model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\")\n","processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-stage1')\n","tokenizer_ = processor.tokenizer\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["Here we will modify the model so that we can replace them with KANs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["in1 = 256\n","in2 = 1024\n","out1 = 1024\n","out2 = 256\n","replace_specific_layers(model.decoder, 'fc1',in1, out1,KAN)\n","replace_specific_layers(model.decoder, 'fc2',in2, out2,KAN)\n"]},{"cell_type":"markdown","metadata":{},"source":["Paramters set for processor "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:45.585582Z","iopub.status.busy":"2024-05-22T09:29:45.585288Z","iopub.status.idle":"2024-05-22T09:29:45.591743Z","shell.execute_reply":"2024-05-22T09:29:45.590740Z","shell.execute_reply.started":"2024-05-22T09:29:45.585558Z"},"trusted":true},"outputs":[],"source":["model.config.eos_token_id = processor.tokenizer.sep_token_id\n","model.config.max_length = 512\n","model.config.early_stopping = True\n","model.config.no_repeat_ngram_size = 3\n","model.config.length_penalty = 2.0\n","model.config.num_beams = 4\n","model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n","model.config.pad_token_id = processor.tokenizer.pad_token_id\n","\n","batch_size = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:45.593388Z","iopub.status.busy":"2024-05-22T09:29:45.593037Z","iopub.status.idle":"2024-05-22T09:29:45.703378Z","shell.execute_reply":"2024-05-22T09:29:45.702523Z","shell.execute_reply.started":"2024-05-22T09:29:45.593356Z"},"trusted":true},"outputs":[],"source":["train_dataset = ArabicSTRDataset(root_dir=root_dir,\n","                           df=train_df,\n","                           processor=processor,\n","                           tokenizer=processor.tokenizer,\n","                           max_target_length=100)\n","\n","eval_dataset = ArabicSTRDataset(root_dir=root_dir,\n","                           df=val_df,\n","                           processor=processor,\n","                           tokenizer=processor.tokenizer,\n","                           max_target_length=100)\n","\n","test_dataset = ArabicSTRDataset(root_dir=root_dir,\n","                           df=test_df,\n","                           processor=processor,\n","                           tokenizer=processor.tokenizer,\n","                           max_target_length=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:29:45.705364Z","iopub.status.busy":"2024-05-22T09:29:45.705085Z","iopub.status.idle":"2024-05-22T09:29:45.716600Z","shell.execute_reply":"2024-05-22T09:29:45.715746Z","shell.execute_reply.started":"2024-05-22T09:29:45.705341Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:31:38.274829Z","iopub.status.busy":"2024-05-22T09:31:38.274176Z","iopub.status.idle":"2024-05-22T09:31:38.283682Z","shell.execute_reply":"2024-05-22T09:31:38.282889Z","shell.execute_reply.started":"2024-05-22T09:31:38.274794Z"},"trusted":true},"outputs":[],"source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',patience = 5,factor = 0.1,verbose=True)\n","earlystopping = EarlyStopping()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:35:46.384365Z","iopub.status.busy":"2024-05-22T09:35:46.383969Z","iopub.status.idle":"2024-05-22T09:35:46.976807Z","shell.execute_reply":"2024-05-22T09:35:46.975556Z","shell.execute_reply.started":"2024-05-22T09:35:46.384333Z"},"trusted":true},"outputs":[],"source":["hist_ = tune_model(100,model,train_dataloader,eval_dataloader,\\\n","               optimizer,device,tokenizer_ , scheduler,earlystopping=earlystopping)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T09:35:36.108972Z","iopub.status.busy":"2024-05-22T09:35:36.108268Z","iopub.status.idle":"2024-05-22T09:35:37.099679Z","shell.execute_reply":"2024-05-22T09:35:37.098538Z","shell.execute_reply.started":"2024-05-22T09:35:36.108940Z"},"trusted":true},"outputs":[],"source":["#!rm -rf /kaggle/working/*"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5050563,"sourceId":8470273,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
