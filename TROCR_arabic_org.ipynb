{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! if [ ! $pip_done ]; then pip install -q transformers ;fi \n",
    "! if [ ! $pip_done ]; then pip install -q datasets jiwer ;fi \n",
    "! if [ ! $pip_done ]; then pip install -q sentencepiece ;fi \n",
    "\n",
    "pip_done = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/TROCR_arabic') #change this to the name of the repo\n",
    "from models import build_model\n",
    "from tools import EarlyStopping, tune_model\n",
    "from data import train_test_split_ , perPixel_mean_std, perChannel_mean_std, build_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/input/str-arabic-dataset/Arabic_words_train\"\n",
    "column_names = ['image_path', 'text']\n",
    "df = pd.read_csv(\"/kaggle/input/str-arabic-dataset/Arabic_words_train/gt.txt\",names = column_names)\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "\n",
    "test_df , val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, val_df,test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the data loader here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicSTRDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, tokenizer, max_target_length):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get file name and text\n",
    "        file_name = self.df.iloc[idx]['image_path']\n",
    "        text = self.df.iloc[idx]['text']\n",
    "\n",
    "        # Prepare image (resize and normalize)\n",
    "        image_path = f\"{self.root_dir}/{file_name}\"\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        # Encode the text\n",
    "        labels = self.tokenizer(text, padding=\"max_length\", max_length=self.max_target_length, return_tensors=\"pt\").input_ids\n",
    "        labels = labels.squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": labels}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the pretrained model using gpt 2 as tokenizer and processor and for the backbone of the network we are using vision transormer with Deit archietcures and pretrained weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\")\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-stage1')\n",
    "tokenizer_ = processor.tokenizer\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramters set for processor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 512\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArabicSTRDataset(root_dir=root_dir,\n",
    "                           df=train_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=processor.tokenizer,\n",
    "                           max_target_length=100)\n",
    "\n",
    "eval_dataset = ArabicSTRDataset(root_dir=root_dir,\n",
    "                           df=val_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=processor.tokenizer,\n",
    "                           max_target_length=100)\n",
    "\n",
    "test_dataset = ArabicSTRDataset(root_dir=root_dir,\n",
    "                           df=test_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=processor.tokenizer,\n",
    "                           max_target_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = optimizer.lr_scheduler.ReduceLROnPlateau(optimizer,'min',patience = 5,factor = 0.1,verbose=True)\n",
    "earlystopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ = tune_model(100,model,train_dataloader,eval_dataloader,\\\n",
    "               optimizer,device,tokenizer_ , scheduler,earlystopping=earlystopping)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
